{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse #renamed to urlib.parse in python 3\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for scraping listings from Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initDriver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\") # runs chrome without actually opening the chrome window\n",
    "    # options.add_argument(\"--incognito\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def initSoup(driver):\n",
    "    html_content = driver.page_source\n",
    "    return BeautifulSoup(html_content,\"html.parser\")\n",
    "\n",
    "def getRootUrl(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    root_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "    return root_url\n",
    "\n",
    "def waitForListingElements(driver):\n",
    "    # listing container\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, \"//div[@itemprop='itemListElement']\")))\n",
    "    \n",
    "    # pagination container\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CLASS_NAME, \"p1j2gy66\")))\n",
    "    \n",
    "\n",
    "def scrapeListings(driver, soup, root_url): # 1 page\n",
    "    listings = soup.find_all(\"div\",{\"itemprop\":\"itemListElement\"})\n",
    "    page_data = pd.DataFrame(columns=[\"Place type\", \"Room type\",\"Location\", \"Rating\", \"Total Reviews\", \"Price/night (SGD)\", \"Total Price (SGD)\", \"Link\"])\n",
    "    for listing in listings:\n",
    "        try:\n",
    "            title = listing.find(\"div\",{\"data-testid\":\"listing-card-title\"}).text.strip().split(\"in\")\n",
    "            room_type = title[0].strip()\n",
    "            if room_type.lower() == \"room\":\n",
    "                place_type = \"Room\"\n",
    "            else:\n",
    "                place_type = \"Entire home\"\n",
    "            location = title[1].strip()\n",
    "            rating = listing.find(\"div\",{\"class\":\"t1a9j9y7\"}).text.strip().split()[0]\n",
    "            if rating != \"New\":\n",
    "                totalReviews = listing.find(\"div\",{\"class\":\"t1a9j9y7\"}).text.strip().split()[6]\n",
    "            else:\n",
    "                totalReviews = 0\n",
    "            price = listing.find(\"span\",{\"class\":\"_11jcbg2\"}).text.strip().split()[0]\n",
    "            price_tax = listing.find(\"div\",{\"class\":\"_i5duul\"}).find(\"div\",{\"class\":\"_10d7v0r\"}).text.strip().split()[0]\n",
    "            link = listing.find(\"a\", {\"class\":\"l1ovpqvx\"}).get(\"href\")\n",
    "            # Reconstruct the absolute link\n",
    "            link = root_url+link\n",
    "            current_data = pd.DataFrame({\n",
    "                \"Place type\":[place_type],\n",
    "                \"Room type\": [room_type],\n",
    "                \"Location\": [location],\n",
    "                \"Rating\":[rating],\n",
    "                \"Total Reviews\":[totalReviews],\n",
    "                \"Price/night (SGD)\":[price],\n",
    "                \"Total Price (SGD)\":[price_tax],\n",
    "                \"Link\":[link]\n",
    "            })\n",
    "            page_data = pd.concat([page_data, current_data], axis=0)\n",
    "            # print(f\"Title: {title}\\nRating: {rating}/5\\nPrice: {price}\\nTotal Price: {price_tax}\\nLink: {link} \\n\\n\")\n",
    "        \n",
    "        # skip the current listing if contain missing info/error\n",
    "        except:\n",
    "            continue\n",
    "    return page_data\n",
    "\n",
    "def getnextPageURL(soup, root_url):\n",
    "    next_link = soup.find(\"a\",{\"aria-label\":\"Next\"})\n",
    "    # check for last page\n",
    "    if next_link:\n",
    "        next_page = root_url+next_link.get(\"href\")\n",
    "        return next_page\n",
    "    else:\n",
    "        return next_link # will return false\n",
    "\n",
    "def quitProgram(driver, airbnb_data):\n",
    "    driver.quit()\n",
    "    file_path = Path(\"./dataset/airbnb.csv\")\n",
    "    file_path.parent.mkdir(parents = True, exist_ok = True)\n",
    "    airbnb_data.to_csv(file_path, index = False)\n",
    "    print(f\"Data saved to {file_path}...\")\n",
    "\n",
    "'''====================================================================='''\n",
    "\n",
    "def scrapeListingDetails(url):\n",
    "    driver = initDriver()\n",
    "    listing_details = {}\n",
    "    driver.get(url)\n",
    "    # close the pop-up dialog for translation\n",
    "    try:\n",
    "        modal = WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@role='dialog']\")))\n",
    "        close_button = modal.find_element(By.XPATH, \"//button[@aria-label='Close']\")\n",
    "        close_button.click()\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except NoSuchElementException:\n",
    "        print(\"Couldn't find translation modal\") \n",
    "    try:\n",
    "        # 1\n",
    "        soup = initSoup(driver)\n",
    "        listing_details.update(scrapeRoomContents(soup))\n",
    "\n",
    "        # 2\n",
    "        soup = initSoup(driver)\n",
    "        listing_details.update(scrapeLatLong(soup))   \n",
    "\n",
    "        # 3 - only need pass the url in 1 of the dictionary for merging with the original dataframe\n",
    "        # click the show all amenitites button\n",
    "        amentities_sect = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@data-section-id='AMENITIES_DEFAULT']\")))\n",
    "        amenities_button = WebDriverWait(amentities_sect, 10).until(\n",
    "        EC.element_to_be_clickable((By.TAG_NAME, \"button\")))\n",
    "        amenities_button.click()\n",
    "        amenities_modal = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//div[@role='dialog']\")))\n",
    "        # current_url = driver.current_url\n",
    "        soup = initSoup(driver)\n",
    "        listing_details.update(scrapeAmenities(soup, url))\n",
    "\n",
    "        # 4\n",
    "        soup = initSoup(driver)\n",
    "        listing_details.update(scrapeRatings(soup))\n",
    "\n",
    "        # 5 \n",
    "        soup = initSoup(driver)\n",
    "        listing_details.update(scrapeHostDetails(soup))\n",
    "    # skip the current listing, scrape again later\n",
    "    # except Exception as e:\n",
    "    #     driver.quit()\n",
    "    #     listing_details = {\"Link\":url}\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return pd.DataFrame([listing_details])\n",
    "\n",
    "def scrapeRoomContents(soup):\n",
    "    room_contents = soup.find(\"div\", {\"class\":\"o1kjrihn\"}).find_all(\"li\", {\"class\":\"l7n4lsf\"})\n",
    "    bedrooms, beds, bathrooms = 0, 0, 0\n",
    "    for content in room_contents:\n",
    "        content = content.text.strip(\"Â· \")\n",
    "        if 'bedroom' in content:\n",
    "            bedrooms = content.split(' ')[0]\n",
    "        elif 'beds' in content:\n",
    "            beds = content.split(' ')[0]\n",
    "        elif 'bathroom' in content:\n",
    "            bathrooms= content.split(' ')[0]\n",
    "            try: # set bathrooms to 1 regardless of the desc like private etc.\n",
    "                int_value = int(bathrooms)\n",
    "            except ValueError:\n",
    "                bathrooms = 1\n",
    "        airbnb_room_contents = {\n",
    "            \"Bedrooms\":bedrooms,\n",
    "            \"Beds\":beds, \n",
    "            \"Bathrooms\":bathrooms,\n",
    "        }\n",
    "\n",
    "    return airbnb_room_contents\n",
    "\n",
    "def scrapeRatings(soup):\n",
    "    ratings = soup.find_all(\"div\", {\"class\":\"l925rvg\"})\n",
    "    cleanliness, accuracy, checkIn, communication, location, value = 0, 0, 0, 0, 0, 0\n",
    "    for rating in ratings:\n",
    "        name = rating.contents[0].text\n",
    "        number = rating.contents[1].text\n",
    "        if name == \"Cleanliness\":\n",
    "            cleanliness = number\n",
    "        elif name == \"Accuracy\":\n",
    "            accuracy = number\n",
    "        elif name == \"Check-in\":\n",
    "            checkIn = number\n",
    "        elif name == \"Communication\":\n",
    "            communication = number\n",
    "        elif name == \"Location\":\n",
    "            location = number\n",
    "        elif name == \"Value\":\n",
    "            value = number\n",
    "    airbnb_ratings = {\n",
    "        \"Cleanliness Rating\":cleanliness,\n",
    "        \"Accuracy Rating\":accuracy,\n",
    "        \"Check-in Rating\":checkIn,\n",
    "        \"Communication Rating\":communication,\n",
    "        \"Location Rating\":location,\n",
    "        \"Value Rating\":value,\n",
    "    }\n",
    "    \n",
    "    return airbnb_ratings\n",
    "\n",
    "def scrapeAmenities(soup, url):\n",
    "    amenities = soup.find_all(\"div\", {\"class\":\"twad414\"})\n",
    "    airbnb_amenities = []\n",
    "    for amenity in amenities:\n",
    "        if (amenity.text.startswith(\"Unavailable\")):\n",
    "            continue\n",
    "        airbnb_amenities.append(amenity.text)\n",
    "    airbnb_amenities = {\n",
    "        \"Amenities\":airbnb_amenities,\n",
    "        \"Link\":url\n",
    "    }\n",
    "\n",
    "    return airbnb_amenities\n",
    "\n",
    "def scrapeHostDetails(soup):\n",
    "    host_superhost = soup.find(\"span\", {\"class\":\"s2nv573\"})\n",
    "    if host_superhost and host_superhost.text == \"Superhost\":\n",
    "        host_superhost = True\n",
    "    else:\n",
    "        host_superhost = False\n",
    "    host_reviews = soup.find(\"span\", {\"data-testid\":\"Reviews-stat-heading\"})\n",
    "    host_rating = soup.find(\"div\", {\"class\":\"ruujrrq\"})\n",
    "    host_reviews = host_reviews.text if host_reviews else float(np.nan)\n",
    "    host_rating = host_rating.text if host_rating else float(np.nan)\n",
    "\n",
    "    airbnb_host_details = {\n",
    "        \"Superhost\":host_superhost,\n",
    "        \"Host Reviews\":host_reviews,\n",
    "        \"Host Rating\":host_rating,\n",
    "    }\n",
    "\n",
    "    return airbnb_host_details\n",
    "\n",
    "def scrapeLatLong(soup):\n",
    "    script = soup.find(\"script\", string=lambda x: x and 'lat' in x and 'lng' in x)\n",
    "    if script:\n",
    "        match = re.search(r'\"lat\":([\\d.]+),\"lng\":([\\d.]+)', script.text)\n",
    "        if match:\n",
    "            latitude = match.group(1)\n",
    "            longitude = match.group(2)\n",
    "    airbnb_lat_long =  {\n",
    "        \"Latitude\":latitude,\n",
    "        \"Longitude\":longitude,\n",
    "    }\n",
    "\n",
    "    return airbnb_lat_long  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape basic information of listings from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to dataset\\airbnb.csv...\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.airbnb.com.sg/s/Bangkok--Thailand/homes?refinement_paths%5B%5D=%2Fhomes&checkin=2024-10-04&checkout=2024-10-10&adults=3&tab_id=home_tab&query=Bangkok%2C%20Thailand&flexible_trip_lengths%5B%5D=one_week&monthly_start_date=2024-08-01&monthly_length=3&monthly_end_date=2024-11-01&price_filter_input_type=0&price_filter_num_nights=6&channel=EXPLORE&date_picker_type=calendar&place_id=ChIJ82ENKDJgHTERIEjiXbIAAQE&source=structured_search_input_header&search_type=user_map_move&search_mode=regular_search&ne_lat=13.810393924485789&ne_lng=100.5597668742775&sw_lat=13.71428581582692&sw_lng=100.48846329668004&zoom=12.786708747368644&zoom_level=12.786708747368644&search_by_map=true\"\n",
    "root_url = getRootUrl(url)\n",
    "driver = initDriver()\n",
    "\n",
    "airbnb_data = pd.DataFrame(columns=[\"Place type\", \"Room type\", \"Location\", \"Rating\", \"Total Reviews\", \"Price/night (SGD)\", \"Total Price (SGD)\", \"Link\"])\n",
    "\n",
    "try:\n",
    "    driver.get(url)\n",
    "    while True:\n",
    "        waitForListingElements(driver)\n",
    "        soup = initSoup(driver)\n",
    "        data = scrapeListings(driver, soup, root_url)\n",
    "        airbnb_data = pd.concat([airbnb_data, data], axis = 0)\n",
    "        result = getnextPageURL(soup, root_url)\n",
    "        if(result):\n",
    "            driver.get(result)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "\n",
    "finally:\n",
    "    quitProgram(driver, airbnb_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape additional information from each listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "Amenities has been successfully merged into data\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/airbnb.csv\", header=0)\n",
    "listing_url = data[\"Link\"].to_list()\n",
    "count = 0\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = [executor.submit(scrapeListingDetails, url) for url in listing_url]\n",
    "    for future in as_completed(futures):\n",
    "        results.append(future.result())\n",
    "        count += 1\n",
    "        print(count)\n",
    "final_data = pd.concat(results, axis=0)\n",
    "data = data.merge(final_data, how=\"inner\", on=\"Link\")\n",
    "data = data.reindex(columns = [\"Place type\", \"Room type\", \"Location\", \"Latitude\", \"Longitude\",\n",
    "    \"Price/night (SGD)\", \"Total Price (SGD)\", \"Bedrooms\", \"Beds\", \"Bathrooms\",\n",
    "    \"Superhost\", \"Host Reviews\", \"Host Rating\", \"Total Reviews\", \"Rating\",\n",
    "    \"Cleanliness Rating\", \"Accuracy Rating\", \"Check-in Rating\",\n",
    "    \"Communication Rating\", \"Location Rating\", \"Value Rating\", \"Amenities\", \"Link\"])\n",
    "file_path = Path(\"./dataset/airbnb.csv\")\n",
    "file_path.parent.mkdir(parents = True, exist_ok = True)\n",
    "data.to_csv(file_path, index = False)\n",
    "print(\"Amenities has been successfully merged into data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n267    False\n268    False\n269    False\n270    False\n271    False\nName: Link, Length: 272, dtype: bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m new_data \u001b[38;5;241m=\u001b[39m scrapeListingDetails(link)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_to_update:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(new_data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, col])\n\u001b[0;32m     27\u001b[0m     data\u001b[38;5;241m.\u001b[39mloc[data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLink\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mlink, col] \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, col]\n",
      "File \u001b[1;32mc:\\Users\\piers\\PythonProjects\\WebScraper\\webscrape\\Lib\\site-packages\\pandas\\core\\indexing.py:2575\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m-> 2575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\PythonProjects\\WebScraper\\webscrape\\Lib\\site-packages\\pandas\\core\\indexing.py:2527\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2526\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\PythonProjects\\WebScraper\\webscrape\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piers\\PythonProjects\\WebScraper\\webscrape\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m--> 418\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "File \u001b[1;32mc:\\Users\\piers\\PythonProjects\\WebScraper\\webscrape\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6059\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   6056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   6057\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   6058\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 6059\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: 0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n267    False\n268    False\n269    False\n270    False\n271    False\nName: Link, Length: 272, dtype: bool"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/airbnb.csv\", header=0)\n",
    "null_mask = data.isna().any(axis=1)\n",
    "null_url = data[null_mask][\"Link\"].to_list()\n",
    "\n",
    "columns_to_update = [\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Bedrooms\",\n",
    "    \"Beds\",\n",
    "    \"Bathrooms\",\n",
    "    \"Superhost\",\n",
    "    \"Host Reviews\",\n",
    "    \"Host Rating\",\n",
    "    \"Cleanliness Rating\",\n",
    "    \"Accuracy Rating\",\n",
    "    \"Check-in Rating\",\n",
    "    \"Communication Rating\",\n",
    "    \"Location Rating\",\n",
    "    \"Value Rating\",\n",
    "    \"Amenities\"\n",
    "]\n",
    "for link in null_url:\n",
    "    new_data = scrapeListingDetails(link)\n",
    "    for col in columns_to_update:\n",
    "        print(data.loc[data[\"Link\"]==link, col])\n",
    "        print(new_data.loc[0, col])\n",
    "        data.loc[data[\"Link\"]==link, col] = new_data.loc[0, col]\n",
    "        print(\"==================\")\n",
    "\n",
    "file_path = Path(\"./dataset/airbnb.csv\")\n",
    "file_path.parent.mkdir(parents = True, exist_ok = True)\n",
    "data.to_csv(file_path, index = False)\n",
    "print(f\"Data saved to {file_path}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.736341903712638 100.55670793589738\n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "\n",
    "r = requests.get('https://www.airbnb.com.sg/rooms/1195697419656803553?check_out=2024-10-10&unique_share_id=F5DB2A4D-DA11-4439-AA2E-687AB8180DD5&slcid=f1247430419743e5bc6306bd76a620a0&s=13&feature=share&adults=3&check_in=2024-10-04&channel=whatsapp&slug=9O4FjOpF&source_impression_id=p3_1721802607_P3n6jNcn1igcjEQg')\n",
    "p_lat = re.compile(r'\"lat\":([-0-9.]+),')\n",
    "p_lng = re.compile(r'\"lng\":([-0-9.]+),')\n",
    "lat = p_lat.findall(r.text)[0]\n",
    "lng = p_lng.findall(r.text)[0]\n",
    "print(lat,lng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this cell only if there are missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place type              0\n",
      "Room type               0\n",
      "Location                0\n",
      "Latitude                0\n",
      "Longitude               0\n",
      "Price/night (SGD)       0\n",
      "Total Price (SGD)       0\n",
      "Bedrooms                0\n",
      "Beds                    0\n",
      "Bathrooms               0\n",
      "Superhost               0\n",
      "Host Reviews            4\n",
      "Host Rating             4\n",
      "Total Reviews           0\n",
      "Rating                  0\n",
      "Cleanliness Rating      0\n",
      "Accuracy Rating         0\n",
      "Check-in Rating         0\n",
      "Communication Rating    0\n",
      "Location Rating         0\n",
      "Value Rating            0\n",
      "Amenities               0\n",
      "Link                    0\n",
      "dtype: int64\n",
      "136    https://www.airbnb.com.sg/rooms/28263438?adult...\n",
      "168    https://www.airbnb.com.sg/rooms/12172154329531...\n",
      "234    https://www.airbnb.com.sg/rooms/2960283?adults...\n",
      "270    https://www.airbnb.com.sg/rooms/11860043030382...\n",
      "Name: Link, dtype: object\n",
      "Place type              0\n",
      "Room type               0\n",
      "Location                0\n",
      "Latitude                0\n",
      "Longitude               0\n",
      "Price/night (SGD)       0\n",
      "Total Price (SGD)       0\n",
      "Bedrooms                0\n",
      "Beds                    0\n",
      "Bathrooms               0\n",
      "Superhost               0\n",
      "Host Reviews            0\n",
      "Host Rating             0\n",
      "Total Reviews           0\n",
      "Rating                  0\n",
      "Cleanliness Rating      0\n",
      "Accuracy Rating         0\n",
      "Check-in Rating         0\n",
      "Communication Rating    0\n",
      "Location Rating         0\n",
      "Value Rating            0\n",
      "Amenities               0\n",
      "Link                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/airbnb.csv\", header=0)\n",
    "print(data.isna().sum())\n",
    "null_mask = data.isna().any(axis=1)\n",
    "# retrieve the URLs with no amenities\n",
    "null_url = data[null_mask][\"Link\"]\n",
    "print(null_url)\n",
    "\n",
    "data = data.dropna()\n",
    "print(data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m root_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_url\u001b[38;5;241m.\u001b[39mscheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_url\u001b[38;5;241m.\u001b[39mnetloc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m airbnb_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice/night (SGD)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Price (SGD)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLink\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:363\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    137\u001b[0m         method,\n\u001b[0;32m    138\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\piers\\WebScraper\\webscrape\\Lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = \"https://www.airbnb.com.sg/s/Bangkok--Thailand/homes?refinement_paths%5B%5D=%2Fhomes&checkin=2024-10-04&checkout=2024-10-10&adults=3&tab_id=home_tab&query=Bangkok%2C%20Thailand&flexible_trip_lengths%5B%5D=one_week&monthly_start_date=2024-08-01&monthly_length=3&monthly_end_date=2024-11-01&price_filter_input_type=0&price_filter_num_nights=6&channel=EXPLORE&date_picker_type=calendar&place_id=ChIJ82ENKDJgHTERIEjiXbIAAQE&source=structured_search_input_header&search_type=user_map_move&search_mode=regular_search&ne_lat=13.810393924485789&ne_lng=100.5597668742775&sw_lat=13.71428581582692&sw_lng=100.48846329668004&zoom=12.786708747368644&zoom_level=12.786708747368644&search_by_map=true\"\n",
    "# url = \"https://www.airbnb.com.sg/s/Indonesia/homes?refinement_paths%5B%5D=%2Fhomes&checkin=2024-07-25&checkout=2024-07-27&adults=2&children=0\"\n",
    "parsed_url = urlparse(url)\n",
    "root_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "airbnb_data = pd.DataFrame(columns=[\"Title\", \"Rating\", \"Price/night (SGD)\", \"Total Price (SGD)\", \"Link\"])\n",
    "try:\n",
    "    while True:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//div[@itemprop='itemListElement']\"))\n",
    "        )\n",
    "        pagination = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CLASS_NAME, \"p1j2gy66\"))\n",
    "        )\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "\n",
    "        listings = soup.find_all(\"div\",{\"itemprop\":\"itemListElement\"})\n",
    "        for listing in listings:\n",
    "            try:\n",
    "                title = listing.find(\"div\",{\"data-testid\":\"listing-card-title\"}).text.strip()\n",
    "                rating = listing.find(\"div\",{\"class\":\"t1a9j9y7\"}).text.strip().split()[0]\n",
    "                price = listing.find(\"span\",{\"class\":\"_11jcbg2\"}).text.strip().split()[0]\n",
    "                price_tax = listing.find(\"div\",{\"class\":\"_i5duul\"}).find(\"div\",{\"class\":\"_10d7v0r\"}).text.strip().split()[0]\n",
    "                link = listing.find(\"a\", {\"class\":\"l1ovpqvx\"}).get(\"href\")\n",
    "                # Reconstruct the absolute link\n",
    "                link = root_url+link\n",
    "                current_data = pd.DataFrame({\n",
    "                    \"Title\":title,\n",
    "                    \"Rating\":rating,\n",
    "                    \"Price/night (SGD)\":price,\n",
    "                    \"Total Price (SGD)\":price_tax,\n",
    "                    \"Link\":[link]\n",
    "                })\n",
    "                airbnb_data = pd.concat([airbnb_data, current_data], axis = 0)\n",
    "                # print(f\"Title: {title}\\nRating: {rating}/5\\nPrice: {price}\\nTotal Price: {price_tax}\\nLink: {link} \\n\\n\")\n",
    "            \n",
    "            # skip the current listing if contain missing info/error\n",
    "            except:\n",
    "                continue\n",
    "        button = soup.find(\"a\",{\"aria-label\":\"Next\"})\n",
    "        # check for last page\n",
    "        if button:\n",
    "            button = root_url+button.get(\"href\")\n",
    "            driver.get(button)\n",
    "        else:\n",
    "            break\n",
    "   \n",
    "finally:\n",
    "    driver.quit()\n",
    "    file_path = Path(\"./dataset/airbnb.csv\")\n",
    "    file_path.parent.mkdir(parents = True, exist_ok = True)\n",
    "    airbnb_data.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Place type           Room type                   Location Rating  \\\n",
      "84   Entire home                Flat  Khet Pom Prap Sattru Phai   4.67   \n",
      "1           Room                Room           Khet Ratchathewi    5.0   \n",
      "194  Entire home  Serviced apartment            Khet Khlong San   4.89   \n",
      "232  Entire home               Hotel                   Watthana    New   \n",
      "264  Entire home                Flat                Ratchathewi    4.8   \n",
      "\n",
      "     Total Reviews  Price/night (SGD) Total Price (SGD)  \\\n",
      "84             215                 32              $202   \n",
      "1                5                 38              $249   \n",
      "194             27                 40              $255   \n",
      "232              0                 41              $245   \n",
      "264            129                 45              $286   \n",
      "\n",
      "                                                  Link  \n",
      "84   https://www.airbnb.com.sg/rooms/11405732?adult...  \n",
      "1    https://www.airbnb.com.sg/rooms/11854250123456...  \n",
      "194  https://www.airbnb.com.sg/rooms/83386563097775...  \n",
      "232  https://www.airbnb.com.sg/rooms/12164162578303...  \n",
      "264  https://www.airbnb.com.sg/rooms/2279684?adults...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/airbnb.csv\")\n",
    "data[\"Price/night (SGD)\"] = data[\"Price/night (SGD)\"].str.replace(\"$\", \"\").astype(\"int\")\n",
    "print(data.sort_values(by=\"Price/night (SGD)\").head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
